# -*- coding: utf-8 -*-
"""cassandradb_pdfquery

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sS2mtVqysSFNeGUE9DO7W_8J9YnZXJZa
"""

grishu_key="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"

# !pip install langchain
# !pip install langchain-community
# !pip install openai
# !pip install -q cassio datasets langchain openai tiktoken
# !pip install pdfplumber

from langchain.vectorstores.cassandra import Cassandra
from langchain.indexes.vectorstore import VectorStoreIndexWrapper
from langchain.llms import OpenAI
from langchain.embeddings import OpenAIEmbeddings

from datasets import load_dataset
import cassio

# !pip install PyPDF2

from PyPDF2 import PdfReader
import os



import pdfplumber
def read_doc(file_path):
    raw_text = ""
    with pdfplumber.open(file_path) as pdf:
        for page in pdf.pages:
            text = page.extract_text()
            if text:
                raw_text += text
    return raw_text



doc=read_doc('budget_speech.pdf')
len(doc)

from typing_extensions import Concatenate
# cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)

llm = OpenAI()
embedding = OpenAIEmbeddings()

import os
from langchain_astradb import AstraDBVectorStore
from langchain_core.documents import Document
from langchain_openai import OpenAIEmbeddings

from datasets import load_dataset
from dotenv import load_dotenv

embedding = OpenAIEmbeddings()
vstore = AstraDBVectorStore(
    collection_name="budget_speech",
    embedding=embedding,
    token=ASTRA_DB_APPLICATION_TOKEN,
    api_endpoint=ASTRA_DB_API_ENDPOINT,

)

from langchain.text_splitter import CharacterTextSplitter
# We need to split the text using Character Text Split such that it sshould not increse token size
text_splitter = CharacterTextSplitter(
    separator = "\n",
    chunk_size = 800,
    chunk_overlap  = 200,
    length_function = len,
)
texts = text_splitter.split_text(doc)

len(texts)

vstore.add_texts(texts[0:50])
print("Inserted %i headlines." % len(texts[:50]))

astra_vector_index = VectorStoreIndexWrapper(vectorstore=vstore)

first_question = True
while True:
    if first_question:
        query_text = input("\nEnter your question (or type 'quit' to exit): ").strip()
    else:
        query_text = input("\nWhat's your next question (or type 'quit' to exit): ").strip()

    if query_text.lower() == "quit":
        break

    if query_text == "":
        continue

    first_question = False

    print("\nQUESTION: \"%s\"" % query_text)
    answer = astra_vector_index.query(query_text, llm=llm).strip()
    print("ANSWER: \"%s\"\n" % answer)

    print("FIRST DOCUMENTS BY RELEVANCE:")
    for doc, score in vstore.similarity_search_with_score(query_text, k=4):
        print("    [%0.4f] \"%s ...\"" % (score, doc.page_content[:100]))

